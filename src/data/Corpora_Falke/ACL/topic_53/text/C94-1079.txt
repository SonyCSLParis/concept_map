1. Introduction
Principle-based grammars, such as Government-Binding (GB) theory (Chomsky, 1981; Haegeman, 1991), offer many advantages over rule-based and unification-based grammars, such as the universality of principles and modularity of components in the grammar. Principles are constraints over X-bar structures. Most previous principle-based parsers, e.g., (Dorr, 1991; Font, 1991; Johnson, 1991), essentially generate all possible X-bar structures of a sentence and then use the principles to filter out the illicit ones. The drawback of this approach is the inefficiency due 1;o the large number of candidate structures to be. filtered out. The problem persists even when w~rions techniques such as optimal ordering of principles (Fong, 1991), and corontining (Dorr, 1991; Johnson, 1991) are used. This problem may also account for the fact that these parsers are experimental and have limited coverage.
This paper describes an efficient, broadcoverage, principle-based parser, called PRIN- CIPAR. The main innovation in PRINCIPAR is that it applies principles to descriptions o17 X- bar structures rather than the structures themselves. X-bar structures of a sentence are only built when their descriptions have satisfied all the pri ncil)les.
O dynamic data
Figure 1: '.Pile architecture of PRINCIPAR
Figure I shows the architecture of PRIN- CIPAR. Sentence analysis is divided into three steps. The lexical analyser first converts the input sentence into a set of texical items. Then, a message passing algorithm for OB-parsing is used to construct a shared parse forest. Finally, a parse tree retriever is used to enumerate the parse trees.
The key idea of the parsing algorithm was presented in (tin, 199:1). This paper presents some implementation details and experimental results.
2. Parsing by Message Passing
The parser in PIHNCIPAR is based on a message-passing framework proposed by ],in (1993) and l,in and Ooebel (1993), which uses a network to encode the grammar. The nodes in tile grammar network represent grammatical categories (e.g., NP, Nbar, N) or subcategories, such as V:NP (transitive verbs that take NPs as complements). The links in the network re.present relationships bel;ween the categories. GB-principles are implemented as local constraints attached to the nodes and perco la t ion cormtra in ts attached to links in the network. F igure'2 depicts ~ port:ion C" tile gr ;unmar network for |Dnglish.
' 2 \ I t " "IP
,. ' . . . . . . . . . . ': '....".v.v.v.v.v.v.v; ................. .'"' "" ,~ adjullct dominance conlplement domln:lnce specialization specifier doininailce head donlinanee barrier
Figure 2: A Grtunma.r Network
Th(;re ~u'e two types of l inks in 1,he network: subsumpt ion l{nks and dominance l inks.
• [l.'here is a SlXi)sttln[)tiOlX link ['rotn (v l;o fl if a subsume.s ft. For exa,ini)le , since V subsumes V:NP and V:CP, l;here is a, sul)smnption l ink from V to ca.oh ()11o, of them.
• There. is a donxhia.nce l ink frolil node (v i.o /7 i f /7 cfl, ll })e imme.dia.tely doininal~ed by O& l.'~Ol ' CXi/dl lp lc, SillCC a.IX Nl)a.r l i i&y i lt lmedia£cly dominate a. PP adjimct,, t;here is a dominance link from Nbar to pp.
A dominance link fi:om a to fl is a.ssoci~ted with an integer id that determii les tile linear order between fl and other cat;egories dolnim~t(xl t)y a, and a, binary att;ril)ute to specify whether fl is optional or oblig~l;ory. I t ln order to simplify the diagrain, we did nol. label tile links with their ids in l"igure 2. [nstead, the precedence between dominance links is ilMie~t>ed l)y their
Input sentences a.rc p;u'sed by passing me.ssa.ges iu t,he gramm;u' network. 'l.'he nodes ill the nel, wor]( are compul, ing agents t;lxi~t comnulnica.t.e wil;h e;~ch oi l ier 1)y sending messa,ges in tile rcv(HJso direcl, ion of the links ilx the. network. I']acll node ha.s a. local n lemory tlxa.t, sDol'es a. set of it;ellx.~. Ail il;em is a tr iplet thai; represe.nts a. (possibly intern plei, e) X-ba, r strltci>ll I'(? [ t :
<str , ar t , s rc>,where ~tr is an intx_'ger interva.l [i,j] denoi, ing t:ixe i'i~h Lo j'l, tl word ill I, he ill[)llt; still;el]eel art is the al;trilml,c vMues of the. reel; node o[ the X-bar st;rtlCtAll:(':; ~Uid src is i'~ set o[ St)Ill'CO mess~.~ges Prom which this item is combined. The source i~lessa,ges represent inlinedi~te constituctlLs o[ the reel; node. li',a.ch node in l, he grannil lu: network has a. conll) letion I)redicate tllal, detertllillCS whether a.n ilieln a.t l;lie node. is "coinplete," ilx w i lM i ca.se the it;elXl is sent a.s a, inessltge 1;o el;tier l l()dOS i l l 1~110 ]X}VOI'SC direct ion of the links.
~Vilen a, node receives mi itcnl> il; adiLel31pts {o (:onll)ine the itenl w i th il;ems ['rein other nodes 1,o forln Hew il;enis. 'l~wo it;ores
<[ i , , j l ] , A , , S ,> a.nd <[ i2 , j2 ] , A,2, S~,> can I)e combilxed if
• ' " a,(Ijacent to each ] l, heir Slll'[a.ce sl, riilgs Arc el, her: i7 - : jl-I-1.
2. t i ieir a.tl, r ibute vMues At mid A~ a.re t lHifli~ble..
{{. t i l e SOtlrc(~ lTxessa,~es COTHe Vii/~ d i f fe . rent
Ii,,ks: li,,ks(,g,) r~ li,,ks(S,~) =-- (k, where links(,q) is a. I'illlC~iOlX {hal,> given i~ set o[ nlessa.ges, returl is the sel; of l inks via which the iiicssa.ges a, rrived.
{l'he result o[ I~ixe colnbinM;ion is a. [leW il;Oll;l: <[il,.i~], ,mil 'y(A,, A2), S, U S.~>.
The new il;em represelxt:s a, la,rger N-ba, r sl;ruct,u re result;i ng from t, hc combinat ion of the two snla.ller cues. 111 1;lie new it;era s<%isfles the loca.l constraint, o[ I;he node it is considered valid a.nd sa.ved inl;o the local lnOIxlory. ()l:herwise, ig is disca.rded. A valid ito.nl si~t;isfying i;he comsLarting poinl, s, e.g, (J precedes IP under Char since the link leading to (J is to I;he left, of t.he link leading 1,o 1 P.
48.7 pletion predicate of the node is sent further as messages to other nodes.
The input sentence is parsed in the following steps. Step 1: Lex iea l Look-up : Retrieve the lexical entries for all the words in the sentence and create a lexical item for each word sense. A lexical item is a triple: <[i,j], av~lf, av ..... p>, where [i,j] is an interval denoting the position of the word in the sentence; av~lf is the attribute values of the word sense; and av,:o,,,, is the attr ibute values of the complements of the word sense. Step 2: Message Passing: For each lexieel item <[i,j], av~lf, av ..... p>, create an initiM message <[i,j], av~r, 0> and send this message to the grammar network node that represents the category or subcategory of the word sense. When the node receives the initial message, it may forward the message to other nodes or it ma,y combine the message with other messages and send the resulting combination to other nodes. This initiates a message passing process which stops when there are no more messages to be passed around. At that point, the initial message for the next lexical item is fed into the network. Step 3: Build a Shared Parse Forest When all lexieal items have been processed, a shared parse forest for the input sentence can be built by tracing the origins of the messages at the highest node (CP or IP), whose str component is the whole sentence. The parse forest consists of the links of the grammar network that are traversed during the tracing process. The structure of the parse forest is similar to (Billot and Long, 1989) and (Tomita, 1986), but extended to include attribute values.
The parse trees of the input sentence can be retrieved h'om the parse forest one by one. The next section explains how tile constraints attached to the nodes and links in the network ensure that the parse trees satisfy all the principles.
3. Implementat ion of P r inc ip les
GB principles are implemented as local and percolation constraints on the items. Local constraints are attached to nodes in the network. All items at a node must satisfy the node's local constraint, l?ercolation constraints are attached to the links in the network. A message can be sent across a link only if the item satisfies the percolation constraint of the link.
We will only use two examples to give the reader a general idea about how GB principles are interpreted as loc, al and percolation constraints. Interested reader is referred to Lin (1993) for more details.
3.1. Bound ing rpheory
The Bounding Theory (Subjaneency) states that a movement can cross at most one barrier without leaving an intermedia~te trace. An attribute named ~hbarr±0r is used to implement this l)rinciple. A message containing the attribute value -whbarrier iS used to represent an X-bar structure contMnlng a position out ol7 which a wh-constituent has moved, but without yet crossing a barrier. The wdue +whbarrier means that the movement has M- ready crossed one barrier. Certain dominance links in the network are designated as barrier links. Bounding condition is implemented by tile percolation constraints attached to the barrier links, which block any message with +whbarrier and change -whbarrior to +whbarrier before the message is allowed to pass through.
3.2. Case Theory
Case. Theory reqlfires tha.t every lexicM NP be assigned an al)stl'act case. ']'he implementation of case theory in PI{,INCII~AII, is based on the following attribute vaJues: ca, govern, cm.
+ca the head is ,~ c~se assigner -ca the head is not a case assigner +govern the head is a governor -govern the head is not a governor -cr~ an NP m-commanded by the head needs case marking The case filter is implemented as follows:
1. LocM constraints attached to the nodes assign +ca to items that represent X-bar structures whose heads are case assigners (P, actiw.' V, and tensed I).
-No&~. Local C<mstraint - - l ) ] assign +ca to every item
[ assign +ca to items with -passzve assign +ca to items with tense attril)nte
]';very item at NI' node is assigned an a.ttribute value -cm, which means that l;he NI' represented by l, he item needs 1,o be case-marked. The -cm al;tril)ute then propagates with tile item as it is sent to el;her nodes. ']'his item is said t<) be the origin of the -cm attribute.
Barrier links do not Mlow any item with -cm l;o pass through, ])ceause, once the item goes beyond the 1)arri<:r, the origin Of-era will not be governed, let alone casemarked.
Since each node in X-1)ar strncture has at most one governor, if the governor is not a case assigner, the node will not l)e case-marked. Therei'ore, a case-filter violation is detected if +govern -cm - ca cooccur in an item. On the other han<l, if +govern +ca -cm co-ocetlr itl all item, +,;lien the head daughter of th<; it<,m gove rns and case:marks the origin of-cm. 'l'he case-filter condition on the origin of -cm is met. ']'he -cm attril)ute is cleared. The local constraints attached to all the nodes check for the ('.o-occurrences el ca, cm, and govern to ensure <:ase-filter is not violated by any item.
4. Lex icon
The lexicon in PRINCIPAl{ consists of two hash tables: a primary one in memory and a secondary one on disk. Tile secondary hash ta.= ble contains over 90,000 entries, most of which are constructed automatically by applying a set of extraction and conw:rsion rules to etP tries in Oxford Adwmced ],eaner's l)ictionary and Collins English I)ictionary.
When a word is looked up, t;he F, rimary hashtable is searched first. If a,n entry for the word is found, the lexical search is done. Otherwise, the secondary hash table is searched.
The entry retrieved from the secondary LaI)Ie is inserted into the primary one, so, tha,t when the word is encouutered again only in-memory search will be necessary.
The primary hash table is lc, aded from a file a.L l;he system start-up. The file also serves as a buffer for changes to the secondary hash tM)le. When a lexical entry is ad(led or ]nc, dified, it is saved in the file for the prhnary hash table. The entry in the se<:(mdary hash tal)le remains unchanged. Since the i)rimary hash tM)le is a lw~ws consulted first, its entrios override the (;orresponditlg entries in the seco[ldary La})]C. The reason why the buffer in needed is that the secondary hash table is designed ill such a way that update speed is sacrificed for the sake of ef[icie.t retriewd. Therefore, updates to the secondary hash tal)le should I>e done in batch and relatively infrequently.
The tw(>tier organization of the lexicon is transparent to the l)arser. That is, as far as the. parser is concerned, the lexic<m is an o1> jec{, that, given a word or a phrase, returns its lexical entry or ni l if the entry (lees not exist in the lexicon. I,cxical rctrievM is very el[icient, with over 90,000 entries, the average l;ime to retrieve an entry is 0.002 secon<l.
4.1 . Lexical Ent r ies
All, hot@l the lexicon currently ttsed in I)I{IN - C'II>AI{, contains only syl~.tactic information, it; may also be used to hoM other types of ilffof mation. Each lexical entry consists of ai1 eIltry word or phrase and a, list of functions with a,r- ~tllllClltS:
(< en~;ry-~ord-or-phras e> (<tune-name> <arg> . . . <arg>)
(<gunc-name> <arg> . . . <art>)
For exanq)le, (acknowledge
(subcat ((cat v)) (((cat i) -bare inf))) (subcat ( (ca t v ) ) ( ( ( ca t n) ( case acc ) ) ) )
(subcat ( (ca t v ) ) ( ( ( ca t c ) ) ) ) q']le f'/ltlctioII subcat t'eturt/s a stll)c&|,egoriz&- Lion frame of the word. The first argt l tne I l ( ; of t}te function is the attrHmte va,lues of the word itself. The second argument of the function is a list of attribute value vector for the complements of the word. For example, the above entry means that acknowl edge is a verb that takes an IP, NP or CP as the complement. The lexicon is extensible in that users can define new functions to suit their own needs. Current implementation of the lexicon also includes functions ref and phrase, which are explained in the next two subsections.
4.2. Reference Entr ies
The lexicon does not contain separate entries for regular variations of words. When a word is not found in the lexicon, the lexleal retriever strips the endings of the word to recow~'r possible base forms of the word and look them up in the lexicon. For example, when the lc'xieal retriever fails to find an entry for "studies," it searches the lexicon for "studie," "studi" and "study." Only the last one of these has an entry in the lexicon and its entry is returned.
Irregular variations of words are explicitly listed in the lexicon. For example, there is an entry for the word "began." IIowever, the snbcatgorization frames of "begin" are not listed again under "began." Instead, the entry contains a ref fimction which returns a reference to the entry for "begin." (began
(ref ((cat v) (vform ed) -prog-perf-passive (tense past))) (begin (cat))))
The first argument of ref is the attribute values of "began." The second argument contains the base form of the word and a set of attribute names. The lexical items for the word "began" is obtained by unifying its attribute values with the attribute wdues in the lexiea] entry for "begin." The advantage of making references to the base form is that when the base form is modified, one does not have to make changes to the entries for its variations.
4.a. Phrasal Entr ies
]'he lexicon also allows for phrases that consist of multiple words. One of the words in a phrase is designated as the head word. The head word should be a word in the phrase that can undergo morphological changes and is the most in frequent. For example, in the phrase, "down payment," the head word is "payment." In d~e lexicon, a phrase "wl . . . wj . . . . w,,/' is stored as a s t r ing "'Wh . . . 'tOn, 101 . . . 'U,~h_l." That is, the first word in the string is always head word and the words Mter "," should appear before the head word in texts. The runedon phrases converts il, s arguments into a list of phrases where tile entry word is the head. l,'or example, the lexical entry for "paymenC' is as follows: (payment
(subcat ((cat n) (nform norm))) (phrases
(payment, down) (payment, stop) (payment, token) (payment, transfer)))
After retrieving the entry for a word, each phrase in the phrase list is compared with the surrounding words in the sentence. If the phrase is found in the sentence, the entry for the phrase is retrieved froin the lexicon.
5. Reducing Ambiguities
One of the problems with many parsers is that they typically generate far more parses than humans normally do. I"or example, the average number of parses pet' word is 1.35 in (l]lack et al., 1992). That means that their parser produces, on average, 8 parses for a 7-word sentence, 3d parses for a, l%word sentence, and ld4 l)a.rses for a 17-word seiRe.nce, rphe la.rge number of parse trees make tim l~roe(,ssing at later stages more dillicult and error l)ruTte.
PI{INCII)AI{ defines a weight for every parse tree. A weight is associated with every word sense and every link in the parse tree. [Pile weight of the parse tree is the total weight of the links and the word senses ~tt the leaf nodes of the tree.
The packed shared parse forest in PtUN- CIPAI{. is organized in such a way that the parse tree with minimum weight is retrieved first. I~IUNCIPAII, then uses the minimum weight and a predetermined number called BIGWEIGHT, which is currently arbitraryly defined to be 20, to prune the parse forest. Only the parse trees whose weights are less than (minimum weiglit -F BIGWEIGHT/2) are spared and output.
The weights of the links and word senses are determined as follows: e 'I'he links fi'om Xbar to an ad,imlct YP have weight=nlGWEIglIW and all the~ other links have weight=l.0.
• The words in the lexicon ma,y have an attribute rar% which takes wdues from {very, very-very}. If a word sense has the attribute value (rare very), its weight is BIGWEIGIIT. I fa word sense has the attribute value (rare very-very), its weight is 2×BIGWEIGIIT. Otherwise, the weight is 0,
Note that the att;ribute rare is used to indicate the relative frequency among different stmses of the same word.
/II~ /I L bigwe!ght L ', John John V
/~; NP'~/N p /~N~, about Kim read a/ ~b~r read /NP.
a /)N bar N I~P s tory /X N story about Kim (a) (b)
Figure 3: Adjunct links ha,re higher weights
Example 5.1. Comparing the two parses of the sentence "John read the story a,bout Kim" in Figure 3: in (a), lee about Kim] is the co,nplement of "story"; in (b), it is the a.djunct of "read". Since the adjunct dominance link from Vbar to PP has much higher weight than the complement dominance link from Nba.r to PP, the total weight of (a) is much smaller them the weight of (b). Therefore, only (a) is output as the parse tree of the sentence.
Example 5.2. The lexical entry for tlm word "do" is as follows:
7% 7%
" .p v/,. Who Z_~ /bar Who (traCe)V Kim \~, bigweight \ /v% did NP NP love (trace) A A
(a) (b) Kim love
(do (subcat ((cat i) -passive -per~ (auxform do)
-prog (cgorm fin) (tense present))) (subcat ((cat v) (rare very))
(((cat n) (case acc) (nform norm)))) (subcat ((cat v) (rare very-very))
(((cat n) (case ace) (nform norm)) ((cat n) (case acc) (nform norm))))
']'ha.t is "do" (:a.n bc an auxiliary verb, a transitive verb or a (li-trmlsitive verb. [,'igure el shows two parse trees for the sentence "Who did Kim love?" The parse l;ree (a) corrcsI)onds to the correct; understanding of the sentence. hi (b), "did" is analyzed as a bi-tra,nsitive w,'b as in "Who did Kim a fawn'?" lloweww, since the latter sense of the word has an attribute value (rare very-very), tree (17) has much higher weight tha,n tt'ee (a) and only (a,) is otd.lmt, by the i)ai's(~l ..
6. I rnp lementat ion and Exper imenta l Ftesult;s
PRINCII~AR lms been implemented in C-I--I ~. The graphica,1 user interface is developed with a toolkit called interViews. The program runs on SUN Spa.rcstatlons with X-windows. A version without; gral)hica, l user interface can also be run on most Unix machines with GNU g-f-tcompiler.
l,iu m~d Coebel (1993) showed that the COml)lexlty of the message passing algorithm is O(ICl',,.:' ) ro,. co.l;(.xt-f,:ee gra,,~,nars, wl.',',' ~. is the length of input sc'utenco, [C[ is size
Table 1: Experimental Results Example sentences
Who do you think Bill saM Mary expected to see I asked which books he told me that I should read The petition listed the mayor's occup~ttion as attorney and his age a,s 71 lie said evidence was obtained in violation o[' the legal rights of citizens Mr. Nixon, for his part, wouhl oppose intervention ill Cllba without specific provocation The ~Lssembly la.ngu~tge provides a means for w,'iting a progra.m and you are, not concerned with actual memory addresses " Labels can be assigned to a particular instruction step in a source program that identify that step as an entry point for use in subsequent instructions * time (in seconds) taken on a Sparcstation ];~LC.
- - . , I words [ tmte* p~trses :10 -
11 0.76 i3 0.60 t4 13 0.55 4 ]3 0.51 6
19 O.80 2
26 4.13 32 of the grammar (measure by the number of the total length of the phrase structure rules). When attribute values are used in messages, the complexity of the Mgorithm is not yet known. Our experiments have shown that the parser is very fast. Table 1 lists the parsing time and the number of parses for several example sentences. The correct parses for all the sentences in TM)le 1 are returned by the parser. Even though the lexicon is derived from machine readable dictionaries and contains a ]a.rge number of senses for many words, the ratio between the number of parse trees and the sentence length here is well bellow the ratio reported in (Black et al., 1992).
