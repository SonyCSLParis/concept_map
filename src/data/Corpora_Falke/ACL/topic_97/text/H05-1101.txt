1 Introduction
State of the art architectures for machine translation are all based on mathematical models called translation models. Generally speaking, a translation model accounts for all the elementary operations that rule the process of translation between the words and the different word orderings of the source and target languages. Translation models are usually enriched with statistical parameters, to drive the search toward the most likely translation(s). Specialized algorithms are provided for the automatic estimation of these parameters from corpora of translation pairs. Besides the task of natural language translation, statistical translation models are also exploited in other applications, such as word alignment, multilingual document retrieval and automatic dictionary construction. The most successful translation models that are found in the literature exploit finite-state machinery.
The approach started with the so-called IBM models (Brown et al., 1988), implementing a set of elementary operations, such as movement, duplication and translation, that independently act on individual words in the source sentence. These word-toword models have been later enriched with the introduction of larger units such as phrases; see for instance (Och et al., 1999; Och and Ney, 2002). Still, the generative capacity of these models lies within the realm of finite-state machinery (Kumar and Byrne, 2003), so they are unable to handle nested structures and do not provide the expressivity required to process language pairs with very different word orderings. Recently, more sophisticated translation models have been proposed, borrowing from the theory of compilers and making use of synchronous rewriting. In synchronous rewriting, two formal grammars are exploited, one describing the source language and the other describing the target language. Furthermore, the productions of the two grammars are paired and, in the rewriting process, such pairs are always applied synchronously. Formalisms based on synchronous rewriting have been empowered with the use of statistical parameters, and specialized estimation and translation (decoding) algorithms were newly developed. Among the several proposals, we mention here the models presented in (Wu, 1997; Wu and Wong, 1998), (Alshawi et al., 2000), (Yamada and Knight, 2001), (Gildea, 2003) and (Melamed, 2003). In this paper we consider synchronous models based on context-free grammars and probabilistic extensions thereof. This is the most common choice in statistical translation models that exceed the generative power of finite-state machinery. We focus on two associated computational problems that have been defined in the literature. One is the membership problem, which involves testing whether an input string pair can be generated by the model. The other is the translation problem (also called the decoding problem) which involves the search for a suitable translation of an input string/structure. It has been often informally stated in the literature that the use of structured models results in efficient, polynomial time algorithms for the above problems. We show here that sometimes this is not the case. The contribution of this paper can be stated as follows:
• we show that the membership problem is NP- hard, unless a constant bound is imposed on the length of the productions (Section 3);
• we show an exponential time lower bound for the membership problem, in case chart parsing is adopted (Section 3);
• we show that translating an input string into the best parse tree in the target language is NP- hard, even in case productions are bounded in length (Section 4).
Investigation of the computational complexity of translation models has started in (Knight, 1999) for word-to-word models. This paper can be seen as the continuation of that line of research.
2 Synchronous context-free grammars
Several definitions for synchronous context-free grammars have been proposed in the literature; see for instance (Chiang, 2004; Chiang, 2005). Our definition is based on syntax-directed translation schemata (SDTS; Aho and Ullman, 1972), with the difference that we do not impose the restriction that two paired context-free productions have the same left-hand side. As it will be discussed in Section 4, this results in an enriched generative capacity when probabilistic extensions are considered. We assume the reader is familiar with the definition of contextfree grammar (CFG) and with the associated notion of derivation.
Let VN and VT be sets of nonterminal and terminal symbols, respectively. In what follows we need to represent bijections between all the occurrences of nonterminals in two strings over VN ∪ VT . This can be done by annotating nonterminals with indices from an infinite set. We define I(VN ) = {A(t) | A ∈ VN , t ∈ N} and VI = I(VN ) ∪ VT . We write index(γ), γ ∈ V ∗I , to denote the set of all indices (the integers t) that appear in symbols in γ. Two strings γ, γ′ ∈ V ∗I are synchronous if each index in index(γ) occurs only once in γ, each index in index(γ′) occurs only once in γ′, and index(γ) = index(γ′). Therefore synchronous strings have the general form u10A (t1) 11 u11A u20A (tpi(1))
2r u2r, where r ≥ 0, u1i, u2i ∈ V ∗T , A(ti)1i , A (tpi(i))
2i ∈ I(VN ), ti 6= tj for i 6= j and pi is some permutation defined on set {1, . . . , r}. Definition 1 A synchronous context-free grammar (SCFG) is a tuple G = (VN , VT , P, S), where VN , VT are finite, disjoint sets of nonterminal and terminal symbols, respectively, S ∈ VN is the start symbol and P is a finite set of synchronous productions, each of the form [A1 → α1, A2 → α2], with A1, A2 ∈ VN and α1, α2 ∈ V ∗I synchronous strings. The size of a SCFG G is defined as |G| =∑ [A1→α1, A2→α2]∈P |A1α1A2α2|. Based on an example from (Yamada and Knight, 2001), we provide a sample SCFG fragment translating from English to Japanese, specified by means of the following synchronous productions: s1 : [VB→ PRP(1) VB1(2) VB2(3), VB→ PRP(1) VB2(3) VB1(1)] s2 : [VB2→ VB(1) TO(2), VB2→ TO(2) VB(1) ga] s3 : [TO→ TO(1) NN(2), TO→ NN(2) TO(1)] s4 : [PRP→ he, PRP→ kare ha] s5 : [VB1→ adores, VB1→ daisuki desu] s6 : [VB→ listening, VB→ kiku no] s7 : [TO→ to, TO→ wo] s8 : [NN→ music, NN→ ongaku] Note that in production s2 above, the nonterminals VB and TO generated from nonterminal VB2 in the English component are inverted in the Japanese component, where some additional lexical material is also added. In a SCFG, the ‘derives’ relation is defined on synchronous strings in terms of simultaneous rewriting of two nonterminals with the same index. Some additional notation will help us defining this relation precisely. A reindexing is a one-to-one function on N. We extend a reindexing f to VI by letting f(A(t)) = A(f(t)) for A(t) ∈ I(VN ) and f(a) = a for a ∈ VT . We also extend f to strings in V ∗I by letting f(ε) = ε and f(Xγ) = f(X)f(γ), for each X ∈ VI and γ ∈ V ∗I . We say that strings γ1, γ2 ∈ V ∗I are independent if index(γ1) ∩ index(γ2) = ∅. Definition 2 Let G = (VN , VT , P, S) be a SCFG and let γ1, γ2 be synchronous strings in V ∗I . The derives relation [γ1, γ2] ⇒G [δ1, δ2] holds whenever there exist an index t in index(γ1), a synchronous production [A1 → α1, A2 → α2] in P and some reindexing f such that
(i) f(α1α2) and γ1γ2 are independent; and
(ii) γi = γ′iA (t) i γ
′′ i , δi = γ
′′ i , for i = 1, 2.
We also write [γ1, γ2] ⇒sG [δ1, δ2] to explicitly indicate that the derives relation holds through some synchronous production s ∈ P . Since δ1 and δ2 in Definition 2 are synchronous strings, we can define the reflexive and transitive closure of ⇒G, written ⇒∗G. This relation is used to represent derivations in G. In case we have [γ1i−1, γ2i−1] ⇒siG [γ1i, γ2i] for 1 ≤ i ≤ n, n ≥ 1, we also write [γ10, γ20] ⇒σG [γ1n, γ2n], where σ = s1s2 · · · sn. We always assume some canonical form for derivations (as for instance leftmost derivation on the left component). Similarly to the case of context-free grammars, each derivation inG can be associated with a pair of parse trees, that is, one parse tree for each dimension. Back to our example, we report a fragment of a derivation of the string pair [he adores listening to music, kare ha ongaku wo kiku no ga daisuki desu]:
[VB(1), VB(1)] ⇒s1G [PRP(2) VB1(3) VB2(4),
PRP(2) VB2(4) VB1(3)] ⇒s4G [he VB1(3) VB2(4), kare ha VB2(4) VB1(3)] ⇒s5G [he adores VB2(4), kare ha VB2(4) daisuki desu] ⇒s2G [he adores VB(5) TO(6), kare ha TO(6) VB(5) ga daisuki desu].
The translation generated by a SCFG G is a binary relation over V ∗T defined as
T (G) = {[w1, w2] | [S(1), S(1)]⇒∗G [w1, w2], w1, w2 ∈ V ∗T }.
The set of strings that are translations of a given string w1 is defined as:
T (G,w1) = {w2 | [w1, w2] ∈ T (G)}.
A probabilistic SCFG (PSCFG) is a pair (G, pG) where G = (VN , VT , P, S) is a SCFG and pG is a function from P to real numbers in [0, 1] such that, for each A1, A2 ∈ VN , we have:∑
α1,α2 pG([A1 → α1, A2 → α2] = 1.
If for n ≥ 1 and si ∈ P , 1 ≤ i ≤ n, string σ = s1s2 · · · sn is a canonical derivation of the form [S(1), S(1)] ⇒σG [w1, w2], we write pG(σ) =∏n i=1 pG(si). IfD([w1, w2]) is the set of all canonical derivations in G for pair [w1, w2], we write pG([w1, w2]) =
∑ σ∈D([w1,w2]) pG(σ).
3 The membership problem
We consider here the membership problem for SCFG, defined as follows: for input instance a SCFG G and a pair [w1, w2], decide whether [w1, w2] is in T (G). This problem has been considered for instance in (Wu, 1997) for his inversion transduction grammars and has applications in the support of several tasks of automatic annotation of parallel corpora, as for instance segmentation, bracketing, phrasal and word alignment. We show that the membership problem for SCFGs is NP- hard. The result could be derived from the findings in (Melamed et al., 2004) that synchronous rewriting systems as SCFGs are related to the class of so called linear context-free rewriting systems (LCFRSs) and from the result that the membership problem for
LCFRSs is NP-hard (Satta, 1992; Kaji and others, 1994). However, we provide here a direct proof, to simplify the presentation.
Theorem 1 The membership problem for SCFGs is NP-hard.
Proof. We reduce from the three-satisfiability problem (3SAT, Garey and Johnson, 1979). Let 〈U,C〉 be an instance of the 3SAT problem, where U = {u1, . . . , up} is a set of variables and C = {c1, . . . , cn} is a set of clauses. Each clause is a set of three literals from {u1, u1, . . . , up, up}. The general idea of the proof is to use a string pair [w1w2 · · ·wp, wc], where wc is a string representation of C and each wi is a string controlling the truth assignment for the variable ui. We then construct a SCFG G such that each wi can be derived in two possible ways only, using some specialized productions of G, encoding the truth assignment of variable ui. In this way the derivation of the whole string w1 · · ·wp in the left dimension corresponds to a guess of a truth assignment for U . Accordingly, on the right dimension only those symbols of wc will be derived that represent clauses that hold true under the guessed assignment. We need some additional notation. Below we treat C as an alphabet of atomic symbols. We use a function d such that, for every i with 1 ≤ i ≤ p, cd(i,1), cd(i,2), . . . , cd(i,si) is the sequence of all clauses that include literal ui, in the left to right order in which they appear within c1c2 · · · cn, and cd(i,si+1), cd(i,si+2), . . . , cd(i,ti) is the sequence of all clauses that include literal ui, again as they appear within c1c2 · · · cn from left to right. Note that we must have
∑p i=1 ti = 3n. We also use a function e such that, for every 1 ≤ i ≤ p and 1 ≤ j ≤ ti, e(i, j) = j +
∑i−1 k=1 tk (assume
∑0 k=1 tk = 0).
Consider the alphabet {ai, bi | 1 ≤ i ≤ p}. For every i, 1 ≤ i ≤ p, let wi denote a sequence of exactly ti + 1 alternating symbols ai and bi, i.e., wi ∈ (aibi)+ ∪ (aibi)∗ai. For every 1 ≤ i ≤ p, let x(i, 1) = aibi and let x(i, h) = ai (resp. bi) if h is even (resp. odd), 2 ≤ h ≤ ti. Let also x(i, h) = ai (resp. bi) if h is odd (resp. even), 1 ≤ h ≤ ti − 1, and let x(i, ti) = aibi (resp. biai) if ti is odd (resp. even). Therefore we can write wi = x(i, 1)x(i, 2) · · ·x(i, t1) = x(i, 1)x(i, 2) · · ·x(i, t1).
Finally, we need a permutation pi defined on the set {1, . . . , 3n} as follows. Fix i and j with 1 ≤ i ≤ p and 1 ≤ j ≤ ti, and let h be the number of occurrences of the clause cd(i,j) found in the sequence cd(1,1), cd(1,2), . . ., cd(1,t1), cd(2,1), . . ., cd(i,j). Note that we must have 1 ≤ h ≤ 3. Then we set pi(e(i, j)) = 3 · [d(i, j)− 1] + h. We can now define the target instance
〈G, [w,w′]〉 of our reduction. Let [w,w′] = [w1w2 · · ·wp, c1c2 · · · cn]. Let also G = (VN , VT , P, S), with VN = {S} ∪ {Ai | 1 ≤ i ≤ 3n} and VT = C ∪ {ai, bi | 1 ≤ i ≤ p}. The productions below define set P :
(i) for every 1 ≤ i ≤ p: (a) for 1 ≤ h ≤ si:
[Ae(h,i) → x(i, h), Ae(h,i) → ce(i,h)], [Ae(h,i) → x(i, h), Ae(h,i) → ε], [Ae(h,i) → x(i, h), Ae(h,i) → ε];
(b) for si + 1 ≤ h ≤ ti: [Ae(h,i) → x(i, h), Ae(h,i) → ε], [Ae(h,i) → x(i, h), Ae(h,i) → ce(i,h)], [Ae(h,i) → x(i, h), Ae(h,i) → ε];
(ii) [S → A(e(1,1))e(1,1) A (e(1,2)) e(1,2) · · ·
A (e(1,t1)) e(1,t1)
A (pi(e(1,t1))) pi(e(1,t1))
].
It is easy to see that |G|, |w| and |w′| are polynomially related to |U | and |C|. From a derivation of [w,w′] ∈ T (G), we can exhibit a truth assignment that satisfies C simply by reading off the derivation of the left string w1w2 · · ·wp. Conversely, starting from a truth assignment that satisfiesC we can prove w ∈ L(G) by means of (finite) induction on |U |: this part requires a careful inspection of all items in the definition of G. From Theorem 1 we may conclude that algorithms for the membership problem for SCFGs are very unlikely to run in polynomial time. In the literature, several algorithms for this problem have been proposed using tabular methods (chart parsing). In the worst case, all these algorithms run in time Θ(|G| · nk(G)), with G an SCFG and n the length of the input string pair. We know that, unless P = NP, k(G) cannot be a constant. We now prove a lower bound on k(G), providing thereby an exponential time lower bound result for our problem under the assumption of the tabular paradigm. Tabular methods for the membership problem are based on the following representation. Given a synchronous production s : [A1 → B(1)11 · · ·B(r)1r , A2 → B(pi(1))21 · · ·B(pi(r))2r ], (1) the already recognized constituent pairs B1i, B2pi(i) are gather together in several steps, keeping a record of the spanned substrings of the input. To provide a concrete example, if we gather all the B1i’s on the left dimension from left to right, the partial analysis we obtain after the first step can be represented as a state 〈s(1), (i11, j11), (i21, j21)〉, meaning that B11 and B2pi(1) span substrings w1[i11, j11] and w2[i21, j21], respectively.1 At the second step we have a state 〈s(2), (i11, j12), (i21, j21), (i22, j22)〉, meaning that B11B12 together span w1[i11, j12], B2pi(1) spans w2[i21, j21] and B2pi(2) spans w2[i22, j22]. We can see that, for some worst case permutations, the left-to-right strategy demands for increasingly more pairs of indices, so that the exponent in the time complexity linearly grows with r. How much better can we do, if we exploit some strategy other than the left-to-right above? More precisely, we ask how many unconnected spannings a state may require for some worst case permutation pi, under the choice of the best possible parsing strategy for pi itself.
Theorem 2 In the worst case, standard tabular methods for the SCFG membership problem require an amount of timeΩ(|G|nc·
√ r), with r the length of the longest production in G and c a constant.
Proof. For any r ≥ 8 we let q = b√r/2c ≥ b√8/2c = 2, and define a permutation pir on {1, . . . , r}. We view the domain of pir as composed of 2q blocks with q adjacent integers each, possibly followed by r − 2q2 additional “padding” integers, and its codomain as composed of q blocks
1For a string w = a1 · · · an, we write w[i, j] to denote the substring ai+1 · · · aj .
with 2q adjacent integers each, again possibly followed by r − 2q2 “padding” integers. Permutation pir transposes all blocks by sending the j-th element of the i-th block in the domain into the i-th element of the j-th block in the codomain, while mapping each padding integer identically into itself. Formally, for all positive integers i ≤ 2q and j ≤ q, pir(q · (i − 1) + j) = 2q · (j − 1) + i, and for all integers i with 2q2 < i ≤ r, pir(i) = i. We count below how many spans are instantiated by a state that has gathered p constituent pairs, 1 ≤ p ≤ r, in parsing production (1) under any possible strategy. When a constituent pair B1i, B2pir(i) is gathered, we say integer i in the domain of pir and integer pir(i) in the codomain have been pebbled. In this way each span (i, j) in a state corresponds to some run i, i + 1, . . . j of pebbled integers, with either i = 1 or i− 1 unpebbled, and with either j = r or j + 1 unpebbled. We call each such run a segment, and show that every parsing strategy demands at least q = b√r/2c segments either in the domain or in the codomain of pir. We say that a block in the domain of pir is empty, full, or mixed if, respectively, none, all, or some but not all of its elements have been pebbled. Assume that, for a given parsing strategy, the last block that becomes mixed does so when we place the i-th pebble, and the first block that becomes full does so when we place the j-th pebble. Obviously i 6= j: the first pebble placed in a previously empty block can not make it full since every block contains at least 2 elements. If i < j, after placing the i-th pebble and before placing the j-th pebble every block in the domain of pir is mixed. Each of these 2q blocks then contains at least one pebbled element which is adjacent to an unpebbled one and must therefore be either the first or the last element of a segment. The domain of pir then contains at least 2q/2 = q segments. If j < i, after placing the j-th pebble and before placing the i-th pebble at least one block in the domain of pir (e.g., the h-th block) is full, and at least one (e.g., the k-th) is empty. Then, in each of the q blocks in the codomain of pir, the h-th element is pebbled while the k-th is not. Therefore the h-th elements of any two consecutive blocks in the codomain of pir must belong to two distinct segments, since at least one intermediate element is not pebbled. The codomain of pir then contains at least q segments.
4 The translation problem
In this section we consider some formulations of the translation problem for PSCFG that have been proposed in the literature. The most general definition of the translation problem for PSCFG is this: for an input PSCFG Gp = (G, pG) and an input string w, produce a representation of all possible parse trees, along with their probabilities, that are assigned byG to a string in the set T (G,w) under some translation of w. Variant of this definition can be found where the input is a single parse tree for w (Yamada and Knight, 2001), or where the output is a single parse tree, chosen according to some specific criteria (Wu andWong, 1998). To formally study these problems, in what follows we focus on single parse trees associated with derivations in Gp. For a derivation σ of the form [S(1), S(1)]⇒σG [w1, w2], we write tσ,l and tσ,r to denote the left and the right parse trees, respectively, associated with σ. The probability that tσ,r is obtained as a translation of tσ,l through Gp is thus pG([tσ,l, tσ,r]) = pG(σ). Let t be some parse tree; we write y(t) to denote the string in the yield of t. For a string w ∈ V ∗T and a parse tree t, we also consider the probability that t is obtained from w through Gp, defined as: pG([w, t]) = ∑ pG([t′, t]). (2)
We can now precisely define the variants of the translation problem we are interested in. Given as input a PSCFG Gp = (G, pG) and two strings w1, w2 ∈ V ∗T , output the pair of parse trees argmax y(t1) = w1, y(t2) = w2 pG([t1, t2]). (3)
If the synchronous productions in the underlying SCFG G have length bounded by some constant, then the above problem can be solved in polynomial time using extensions of the Viterbi search strategy to parse forests. This has been shown for instance in (Wu and Wong, 1998; Yamada and Knight, 2001; Melamed, 2004).
A second interesting problem is defined as follows. Given as input a PSCFG Gp = (G, pG) and a string w ∈ V ∗T , output the parse tree argmax t pG([w, t]). (4)
Even in case we impose some constant bound on the length of the synchronous productions in G, the above problem is NP-hard, as we show in what follows. We assume the reader is familiar with the definition of probabilistic context-free grammar (PCFG) and with the associated notion of derivation probability (Wetherell, 1980). We denote a PCFG as a pair (G, pG), with G = (VN , VT , P, S) the underlying context-free grammar and pG the associated function providing the probability distributions for the productions in P , conditioned on their lefthand side. A probabilistic regular grammar (PRG) is a PCFG with underlying productions of the form A→ aB orA→ ε, withA,B nonterminal symbols and a a terminal symbol. We consider below a decision problem associated with PRG, called the consensus problem, defined as follows: Given as input a PRG (G, pG) and a rational number d ∈ [0, 1], decide whether there exists a string w in the language generated by G such that pG(w) ≥ d. It has been shown in (Casacuberta and de la Higuera, 2000) that, for a PRG G whose productions have all probabilities expressed by rational numbers, the above problem is NP-complete. (Essentially the same result is also reported in (Lyngso and Pedersen, 2002), stated in terms of hidden Markov models.) We reduce the consensus problem for PRG to a decision version of the problem in (4), called the best translated derivation problem and defined as follows. Given as input a PCFG Gp = (G, pG), a string w ∈ V ∗T and a rational number d ∈ [0, 1], decide whether maxt pG([w, t]) ≥ d. Theorem 3 The best translated derivation problem for the class PSCFG is NP-hard.
Proof. We provide a reduction from the consensus problem for the class PRG with rational production probabilities. The main idea is described in what follows. Given the input PRGGp, we construct a target PSCFG G′p that translates string $ into $, with $ a special symbol. Given as input the string $, G′p simulates all possible derivations of Gp through its own derivations. This is done by encoding the nonterminals appearing in a derivation ρ ofGp within the left component of some derivation σ of G′p, and by encoding the terminal string generated by ρ within the right component of σ. The probability of ρ is also preserved by σ. Let Gp = (G, pG), d be an instance of the consensus problem as above, with G = (VN , VT , P, S). We specify a PSCFG G′p = (G′, pG′) with G′ = (V ′N , {$}, P ′, S) and V ′N = VN ∪ VT . Set P ′ is constructed as follows:
(i) for every (S → aA) ∈ P , s : [S → A(1), S → a(1)] is added to P ′, with pG′(s) = pG(S → aA);
(ii) for every (S → ε) ∈ P , s : [S → $, S → $] is added to P ′, with pG′(s) = pG(S → ε);
(iii) for every a ∈ VT and (A → bB) ∈ P , s : [A → B(1), a → b(1)] is added to P ′, with pG′(s) = pG(A→ bB)
(iv) for every a ∈ VT and (A → ε) ∈ P , s : [A → $, a → $] is added to P ′, with pG′(s) = pG(A→ ε).
Note that the construction of G′p can be carried out in quadratic time in the size of Gp. It is not difficult to see that there exists a derivation of the form S ⇒G a1A1 ⇒G a1a2A2 · · · ⇒G a1a2 · · · anAn if and only if there exist a derivation in G′ associated with unary trees t1 and t2, such that string SA1A2 · · ·An is read from the spine of t1 and string Sa1a2 · · · an is read from the spine of t2. Furthermore, the two derivations are composed of ‘corresponding’ productions with the same probabilities. We conclude that there exists a string w in L(G) with pG(w) > d if and only if there exists a unary tree t with string Sw$ read from the spine such that pG′([$, t]) > d. We discuss below an interesting consequence of
Theorem 3. The SDTS formalism discussed in Section 1 has been extended to the probabilistic case in (Maryanski and Thomason, 1979), called stochastic SDTS (SSDTS). As a corollary to the proof of Theorem 3, we obtain that one can define, through some PSCFG Gp and some fixed string w, a probability distribution pG([w, t]) on parse trees that cannot be obtained through any SSDTS. Without providing the details of the definition of SSDTS, we give here only an outline of the proof. We also assume that the reader is familiar with probabilistic finite automata and with their distributional equivalence with PRG. Consider the PSCFG G′p = (G′, pG′) defined in the proof of Theorem 3, and assume there exists some SSDTS G′′p = (G′′, pG′′) such that, for every tree t, we have pG′′([$, t]) = pG′([$, t]). Since in a derivation of an SDTS the generated trees are always isomorphic, up to some reordering of sibling nodes, we obtain that the productions of G′′ must have the form [S → a(1), S → a(1)], [a → b(1), a → b(1)] and [a → $, a → $]. From these productions we can construct a probabilistic deterministic finite automaton generating the same language as the PRG Gp, and with the same distribution. But this is impossible since there are string distributions defined by some PRG that cannot be obtained through probabilistic deterministic finite automata; see for instance (Vidal et al., 2005). We conclude by remarking that in (Casacuberta and de la Higuera, 2000) it is shown that finding the best output string for a given input string is NP- hard for stochastic SDTS with a single nonterminal in each production’s right-hand side. Our result in Theorem 3, stated for PSCFG, is stronger, since it investigates individual parse trees rather than strings.
5 Concluding remarks
The presented results are based on worst case analysis: further experimental evaluation needs to be carried out on multilingual corpora in order to asses the practical impact of these findings.
Acknowledgment
We are indebted to Dan Melamed and Mark-Jan Nederhof for technical discussion on topics related to this paper. Dan Melamed also suggested to us the problem investigated by Theorem 2. The first author is partially supported by MIUR under project PRIN No. 2003091149 005.
